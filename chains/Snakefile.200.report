# Snakefile.200.report

PLOT_FORMATS = ['png', 'pdf']
TABLE_TYPES = ['percentages', 'reads']
WEBLOGO_UNIT_TYPES = ['probability', 'bits']
FLANKING_SEQUENCE_SOURCES = ['genome', 'transcriptome']

STATS_SAMPLES_SET = set(CLIP_SAMPLES | RNAseq_SAMPLES)
STATS_SAMPLES = [s for s in ALL_SAMPLES_ORDER if s in STATS_SAMPLES_SET] # to the original order
CLIP_SAMPLES_ORDERED = [s for s in ALL_SAMPLES_ORDER if s in CLIP_SAMPLES]

ORIGINAL_SEQREAD_PROCESSED_PAIRS = list(filter(lambda x: x[0] in STATS_SAMPLES_SET, [
{% for sample_name, sample in SAMPLES.items() -%}
  ('{(sample_name)}',
   '{% for acc in sample.runs %}original/{(acc)}.fq.gz {% endfor %}'.split(),
   'sequences/{(sample_name)}.primary.fq.gz',
   'alignments/{(sample_name)}.bam'),
{%- endfor %}
]))


ALL_REPORTING_INGREDIENTS = [
    # prep_report_seq_processing
    'report/tables/sequence-processing.csv',

    # prep_report_class_assignment_props
    expand('report/plots/read-class-proportions.{format}', format=PLOT_FORMATS),
    expand('report/tables/read-class-proportions.{type}.csv', type=TABLE_TYPES),

    # prep_report_pertag_error_profiles
    'report/tables/error-profiles-overview.csv',

    # prep_report_positional_error_profiles
    'report/tables/error-profiles-byposition.csv',
    expand('report/plots/error-profile/error-profile-{sample}.{type}.{format}',
           sample=CLIP_SAMPLES, type=('total', 'del', 'subst'), format=('pdf', 'png')),

    # prep_report_binding_site_weblogos
    expand('report/plots/binding-site/logo-{sample}-{source}-{score_type}-{unit_type}.{format}',
           format=PLOT_FORMATS, sample=CLIP_SAMPLES,
           score_type=BINDINGSITE_LOGO_SCORE_TYPES,
           unit_type=WEBLOGO_UNIT_TYPES, source=FLANKING_SEQUENCE_SOURCES),

    # prep_report_nmer_enrichment
    expand('report/plots/nmer-enrichment/histogram-{sample}-{source}-{score_type}.{format}',
           format=PLOT_FORMATS, sample=CLIP_SAMPLES,
           score_type=FLANKING_NMER_ENRICHMENT_SCORE_TYPES,
           source=FLANKING_SEQUENCE_SOURCES),
    expand('report/tables/nmer-enrichment/nmer-enrichment-{sample}-{source}-{score_type}.csv',
           sample=CLIP_SAMPLES, score_type=FLANKING_NMER_ENRICHMENT_SCORE_TYPES,
           source=FLANKING_SEQUENCE_SOURCES),

    # prep_report_base_pairing_propensity
    expand('report/plots/base-pairing/pairing-{sample}-{source}-{score_type}-preview.png',
           sample=CLIP_SAMPLES, score_type=BASEPAIRING_PROPENSITY_SCORE_TYPES,
           source=FLANKING_SEQUENCE_SOURCES),
    expand('report/plots/base-pairing/pairing-{sample}-{source}-{score_type}.zip',
           sample=CLIP_SAMPLES, score_type=BASEPAIRING_PROPENSITY_SCORE_TYPES,
           source=FLANKING_SEQUENCE_SOURCES),

    # data files needed to be generated before reporting
    expand('alignments/{sample}.sorted.bam.bai', sample=CLIP_SAMPLES | RNAseq_SAMPLES),
]

targets(ALL_REPORTING_INGREDIENTS)
targets([
    FINISHMARK,
    'report.html',
    'report/style.css',
])

rule prep_report_seq_processing:
    input: list(chain(*[spec[1:] for spec in ORIGINAL_SEQREAD_PROCESSED_PAIRS]))
    output: 'report/tables/sequence-processing.csv'
    version: "1"
    threads: 12
    run:
        counting_futures = {}

        with futures.ProcessPoolExecutor(threads) as executor:
            for name, origseqs, primaryfq, alnbam in ORIGINAL_SEQREAD_PROCESSED_PAIRS:
                counting_futures[name] = {
                    'original': [executor.submit(count_reads_fastq, origseqfile)
                                 for origseqfile in origseqs],
                    'primary': executor.submit(count_reads_fastq, primaryfq),
                    'uniqaln': executor.submit(count_uniqmap_alignments_bam, alnbam),
                }

            writer = csv.writer(open(output[0], 'w'))
            writer.writerow(['Sample Name', 'Total Reads', 'Remaining Reads After Processing',
                             'Remaining Reads After Processing (%)',
                             'Uniquely Mappable Reads To Genome',
                             'Uniquely Mappable Reads To Genome (%)'])

            for name, _, _, _ in ORIGINAL_SEQREAD_PROCESSED_PAIRS:
                original = sum(f.result() for f in counting_futures[name]['original'])
                primary = counting_futures[name]['primary'].result()
                uniqaln = counting_futures[name]['uniqaln'].result()
                writer.writerow((name, original, primary, primary / original * 100,
                                 uniqaln, uniqaln / original * 100))


rule prep_report_class_assignment_props:
    input: expand('stats/classprop.{sample}.csv', sample=STATS_SAMPLES)
    output: plots=expand('report/plots/read-class-proportions.{format}', format=PLOT_FORMATS), \
            table=expand('report/tables/read-class-proportions.{type}.csv', type=TABLE_TYPES)
    version: "1"
    run:
        samplespecs = ['{s}:stats/classprop.{s}.csv'.format(s=s) for s in STATS_SAMPLES]
        brandingopt = "--branding '{}'".format(BRANDING) if BRANDING else ''
        plotopts = ' '.join('--write-plot "{}"'.format(f) for f in output.plots)
        tableopts = ' '.join('--write-{type}-csv "report/tables/read-class-proportions.{type}.csv"'.format(type=t) for t in TABLE_TYPES)
        tableclsopts = '--table-classes "{}"'.format(','.join(READ_CLASS_PROP_TABLE_CLASSES))
        plotclsopts = '--plot-classes "{}"'.format(','.join(READ_CLASS_PROP_PLOT_CLASSES))
        classmappings = dict((origcls, (origcls,))
          for origcls in set(READ_CLASS_PROP_TABLE_CLASSES) | set(READ_CLASS_PROP_PLOT_CLASSES))
        classmappings.update(READ_CLASS_PROP_MAPPINGS)
        classmappingopts = ' '.join('--class-mapping "{label}={classes}"'.format(
                                    label=label, classes=','.join(classes))
                                    for label, classes in classmappings.items())

        shell('{REPORT_PLOT_CLASS_PROPORTIONS_CMD} --default-class {READ_CLASS_PROP_DEFAULT} \
            {brandingopt} {plotopts} {tableopts} {plotclsopts} {tableclsopts} \
            {classmappingopts} {samplespecs}')

rule prep_report_pertag_error_profiles:
    input: expand('alignments/{sample}.bam', sample=CLIP_SAMPLES)
    output: 'report/tables/error-profiles-overview.csv'
    version: "1"
    threads: 12
    run:
        samplespecs = ['{s}:alignments/{s}.bam'.format(s=s) for s in CLIP_SAMPLES]
        shell('{REPORT_OVERALL_ERROR_FREQUENCIES_CMD} --parallel {threads} {samplespecs} \
                    > {output} ')

rule prep_report_positional_error_profiles:
    input: expand('erroranalyses/{sample}.errorprof.pickle', sample=CLIP_SAMPLES)
    output: 'report/tables/error-profiles-byposition.csv', \
            expand('report/plots/error-profile/error-profile-{sample}.{type}.{format}',
                   sample=CLIP_SAMPLES, type=('total', 'del', 'subst'), format=PLOT_FORMATS)
    version: "1"
    run:
        samplespecs = ['{s}:erroranalyses/{s}.errorprof.pickle'.format(s=s) \
                       for s in CLIP_SAMPLES]
        shell('{REPORT_ERROR_POSITIONAL_DISTRIBUTION_CMD} \
               --output-csv "report/tables/error-profiles-byposition.csv" \
               --output-plot "report/plots/error-profile/error-profile-{{sample}}.{{type}}.{{format}}" \
               {samplespecs}')

rule prep_report_binding_site_weblogos:
    input: 'erroranalyses/{sample}.catalog.gz'
    output: expand('report/plots/binding-site/logo-{{sample}}-{{seqsource}}-{{score_type}}-{{unit_type}}.{format}',
                    format=PLOT_FORMATS)
    version: '1'
    run:
        mindepth, minscore = BINDINGSITE_LOGO_CUTOFFS[wildcards.score_type]
        output_prefix = os.path.commonprefix(output)
        shell('{REPORT_PLOT_WEBLOGO_FROM_BINDING_SITES_CMD} --score-type {wildcards.score_type} \
                --minimum-depth {mindepth} --minimum-score {minscore} \
                --window {BINDINGSITE_LOGO_WINDOW} --logo-type {wildcards.unit_type} \
                --seq-source {wildcards.seqsource} \
                --output-pdf {output_prefix}df --output-png {output_prefix}ng \
                {input}')

rule prep_report_nmer_enrichment:
    input: 'erroranalyses/{sample}.catalog.gz'
    output: plotoutputs=expand('report/plots/nmer-enrichment/histogram-{{sample}}-{{seqsource}}-{{score_type}}.{format}', \
                format=PLOT_FORMATS), \
            csv='report/tables/nmer-enrichment/nmer-enrichment-{sample}-{seqsource}-{score_type}.csv'
    version: '1'
    run:
        mindepth, minscore = FLANKING_NMER_ENRICHMENT_CUTOFFS[wildcards.score_type]
        output_prefix = os.path.commonprefix(output.plotoutputs)
        shell('{REPORT_NMER_ENRICHMENT_CMD} --score-type {wildcards.score_type} \
                --minimum-depth {mindepth} --minimum-score {minscore} \
                --flanking-window {FLANKING_NMER_ENRICHMENT_WINDOW} \
                --nmer-width {FLANKING_NMER_ENRICHMENT_SIZE} \
                --seq-source {wildcards.seqsource} \
                --output-pdf {output_prefix}df --output-png {output_prefix}ng \
                --output-csv {output.csv} {input}')

rule prep_report_base_pairing_propensity:
    input: 'erroranalyses/{sample}.catalog.gz'
    output: preview='report/plots/base-pairing/pairing-{sample}-{seqsource}-{score_type}-preview.png', \
            package='report/plots/base-pairing/pairing-{sample}-{seqsource}-{score_type}.zip'
    version: '1'
    run:
        mindepth, minscore = BASEPAIRING_PROPENSITY_CUTOFFS[wildcards.score_type]
        shell('{REPORT_BASE_PAIRING_PROPENSITY_CMD} --score-type {wildcards.score_type} \
                --minimum-depth {mindepth} --minimum-score {minscore} \
                --flanking-window {BASEPAIRING_PROPENSITY_WINDOW} \
                --seq-source {wildcards.seqsource} \
                --output-preview-png {output.preview} \
                --output-package {output.package} {input}')

rule mark_finish_time:
    input: ALL_REPORTING_INGREDIENTS
    output: FINISHMARK
    version: '1'
    run:
        print(time.time(), file=open(output[0], 'w'))

rule generate_report:
    input: FINISHMARK
    output: 'report.html', 'report/style.css'
    version: '1'
    run:
        with TemporaryDirectory() as tmpdir:
            metainfo_filename = os.path.join(tmpdir, 'metainfo.pickle')
            metainfo = {
                'project_name': '{( NAME )}',
            }
            pickle.dump(metainfo, open(metainfo_filename, 'wb'))

            shell('{REPORT_FINISH_CMD} --ecliptic-dir "{TOP_DIR}" \
                    --work-dir "{WORK_DIR}" --meta-info report/metainfo.pickle')

