# Snakefile.30.erroranalysis

targets(expand('erroranalyses/{sample}.del.perm.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.mod.perm.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.moddel.perm.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.entropy.perm.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.nonzero.real.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.mod.real.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.moddel.real.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.del.real.gz', sample=list(CLIP_SAMPLES)) +
        expand('erroranalyses/{sample}.entropy.real.gz', sample=list(CLIP_SAMPLES)))


{% for sample_name, sample in SAMPLES.items() %}
rule count_errors_{(sample_name|rule_name)}:
    input: 'alignments/{(sample_name)}.split/done'
    output: prof_pickle='erroranalyses/{(sample_name)}.errorprof.pickle', \
            prof_arraydump='erroranalyses/{(sample_name)}.errorprof.arraydump'
    threads: {( THREADS )}
    version: "2"
    run:
        bamdir = os.path.dirname(input[0])
        errorprof_prefix = os.path.commonprefix(output)
        shell('{COLLECT_ERROR_COUNTS_CMD} {bamdir} resources/{(sample.species)}/genome.fa \
                 {errorprof_prefix} {(sample.maximum_length + 1)} {threads}')
{% endfor %}

rule preprare_readpool:
    input: 'alignments/{sample}.split/done'
    output: 'erroranalyses/{sample}.readpool'
    threads: 12 # somewhat I/O bound task
    version: "1"
    run:
        bamdir = os.path.dirname(input[0])
        species = SAMPLE_SPECIES[wildcards.sample]
        shell('{CROSSFEST_PREPARE_READPOOL_CMD} {bamdir} resources/{species}/genome.fa \
                {output} {threads}')

rule run_alnerror_simulation:
    input: readpool='erroranalyses/{sample}.readpool', \
           errorprofile_array='erroranalyses/{sample}.errorprof.arraydump', \
           errorprofile_pickle='erroranalyses/{sample}.errorprof.pickle'
    output: simout_del='erroranalyses/{sample}.del.perm.gz', \
            simout_mod='erroranalyses/{sample}.mod.perm.gz', \
            simout_moddel='erroranalyses/{sample}.moddel.perm.gz', \
            simout_entropy='erroranalyses/{sample}.entropy.perm.gz'
    threads: {( THREADS )}
    version: "1"
    run:
        outputprefix = os.path.commonprefix([output.simout_del, output.simout_mod,
                                             output.simout_moddel, output.simout_entropy])
        species = SAMPLE_SPECIES[wildcards.sample]
        read_depth = unpickle(input.errorprofile_pickle)[0].sum()
        simulation_depth = crossfest_determine_simulation_depth(read_depth)
        shell('{CROSSFEST_CMD} -i {input.readpool} -e {input.errorprofile_array} \
               -o {outputprefix} -t {threads} -d {simulation_depth}')

rule measure_error_rates:
    input: bamsplit='alignments/{sample}.split/done'
    output: 'erroranalyses/{sample}.nonzero.real.gz', \
            'erroranalyses/{sample}.del.real.gz', \
            'erroranalyses/{sample}.mod.real.gz', \
            'erroranalyses/{sample}.moddel.real.gz', \
            'erroranalyses/{sample}.entropy.real.gz'
    threads: {( THREADS )}
    version: "1"
    run:
        bamdir = os.path.dirname(input[0])
        outputprefix = os.path.commonprefix(output)
        species = SAMPLE_SPECIES[wildcards.sample]
        shell('{MEASURE_CLUSTERED_ERRORS_CMD} {bamdir} \
                    resources/{species}/genome.fa {outputprefix} {threads}')

